{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data quality at scale with PyDeequ\n",
    "\n",
    "Authors: Calvin Wang (calviwan@), Chris Ghyzel (cghyzel@), Joan Aoanan (jaoanan@), Veronika Megler (meglerv@) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You generally write unit tests for your code, but do you also test your data? Incoming data quality can make or break your machine learning application. Incorrect, missing or malformed data can have a large impact on production systems. Examples of data quality issues are:\n",
    "\n",
    "* Missing values can lead to failures in production system that require non-null values (NullPointerException).\n",
    "* Changes in the distribution of data can lead to unexpected outputs of machine learning models.\n",
    "* Aggregations of incorrect data can lead to wrong business decisions.\n",
    "\n",
    "In this practical work, we introduce PyDeequ, an open source Python wrapper over [Deequ](https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/) (an open source tool developed and used at Amazon).  While Deequ is written in Scala, PyDeequ allows you to use its  data quality and testing capabilities from Python and PySpark, the language of choice of many data scientists. PyDeequ democratizes and extends the power of Deequ by allowing you to use it alongside the many data science libraries that are available in that language. Furthermore, PyDeequ allows for fluid interface with [Pandas](https://pandas.pydata.org/) DataFrame as opposed to restricting within Spark DataFrames. \n",
    "\n",
    "Deequ allows you to calculate data quality metrics on your dataset, define and verify data quality constraints, and be informed about changes in the data distribution. Instead of implementing checks and verification algorithms on your own, you can focus on describing how your data should look. Deequ supports you by suggesting checks for you. Deequ is implemented on top of [Apache Spark](https://spark.apache.org/) and is designed to scale with large datasets (think billions of rows) that typically live in a distributed filesystem or a data warehouse. PyDeequ gives you access to this capability, but also allows you to use it from the familiar environment of your Python Jupyter notebook.\n",
    "\n",
    "## Deequ at Amazon \n",
    "\n",
    "Deequ is being used internally at Amazon for verifying the quality of many large production datasets. Dataset producers can add and edit data quality constraints. The system computes data quality metrics on a regular basis (with every new version of a dataset), verifies constraints defined by dataset producers, and publishes datasets to consumers in case of success. In error cases, dataset publication can be stopped, and producers are notified to take action. Data quality issues do not propagate to consumer data pipelines, reducing their blast radius. \n",
    "\n",
    "Deequ is also used within [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html#model-monitor-how-it-works). Now with the availability of PyDeequ, it is finding its way into a broader set of environments - SageMaker Notebooks, AWS Glue, and more.\n",
    "\n",
    "## Overview of PyDeequ\n",
    "\n",
    "Let’s look at PyDeequ’s main components, and how they relate to Deequ (shown in Figure 1). \n",
    "\n",
    "* Metrics Computation — Deequ computes data quality metrics, that is, statistics such as completeness, maximum, or correlation. Deequ uses Spark to read from sources such as Amazon S3, and to compute metrics through an optimized set of aggregation queries. You have direct access to the raw metrics computed on the data.\n",
    "* Constraint Verification — As a user, you focus on defining a set of data quality constraints to be verified. Deequ takes care of deriving the required set of metrics to be computed on the data. Deequ generates a data quality report, which contains the result of the constraint verification.\n",
    "* Constraint Suggestion — You can choose to define your own custom data quality constraints, or use the automated constraint suggestion methods that profile the data to infer useful constraints.\n",
    "* Python wrappers — You can call each of the Deequ functions using Python syntax. The wrappers translate the commands to the underlying Deequ calls, and return their response.\n",
    "\n",
    "\n",
    "\n",
    "## Example \n",
    "\n",
    "As a running example, we use NYC TLC Trip Record Data on Amazon S3. We begin the way many data science projects do: with initial data exploration and assessment in a Jupyter notebook. \n",
    "\n",
    "During the data exploration phase, you’d like to easily answer some basic questions about the data: \n",
    "\n",
    "* Are the fields that are supposed to contain unique values, really unique? Are there fields that are missing values? \n",
    "* How many distinct categories are there in the categorical fields?\n",
    "* Are there correlations between some key features?\n",
    "* If there are two supposedly similar datasets (different categories, or different time periods, say), are they really similar?\n",
    "\n",
    "Then, we’ll show you how to scale this approach to large-scale datasets, using the same code on an EMR cluster. This is how you’d likely do your ML training, and later as you move into a production setting.\n",
    "\n",
    "### Setup: Start a PySpark Session in a SageMaker Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydeequ in /opt/conda/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from pydeequ) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from pydeequ) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.23.0->pydeequ) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.23.0->pydeequ) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.23.0->pydeequ) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.23.0->pydeequ) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "# install PyDeequ via pip \n",
    "pip install pydeequ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-pyspark in /opt/conda/lib/python3.10/site-packages (1.4.5)\n",
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sagemaker-pyspark) (1.26.4)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "pip install sagemaker-pyspark pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdk-11/bin/jaotc\n",
      "jdk-11/bin/jar\n",
      "jdk-11/bin/jarsigner\n",
      "jdk-11/bin/java\n",
      "jdk-11/bin/javac\n",
      "jdk-11/bin/javadoc\n",
      "jdk-11/bin/javap\n",
      "jdk-11/bin/jcmd\n",
      "jdk-11/bin/jconsole\n",
      "jdk-11/bin/jdb\n",
      "jdk-11/bin/jdeprscan\n",
      "jdk-11/bin/jdeps\n",
      "jdk-11/bin/jhsdb\n",
      "jdk-11/bin/jimage\n",
      "jdk-11/bin/jinfo\n",
      "jdk-11/bin/jjs\n",
      "jdk-11/bin/jlink\n",
      "jdk-11/bin/jmap\n",
      "jdk-11/bin/jmod\n",
      "jdk-11/bin/jps\n",
      "jdk-11/bin/jrunscript\n",
      "jdk-11/bin/jshell\n",
      "jdk-11/bin/jstack\n",
      "jdk-11/bin/jstat\n",
      "jdk-11/bin/jstatd\n",
      "jdk-11/bin/keytool\n",
      "jdk-11/bin/pack200\n",
      "jdk-11/bin/rmic\n",
      "jdk-11/bin/rmid\n",
      "jdk-11/bin/rmiregistry\n",
      "jdk-11/bin/serialver\n",
      "jdk-11/bin/unpack200\n",
      "jdk-11/conf/logging.properties\n",
      "jdk-11/conf/management/jmxremote.access\n",
      "jdk-11/conf/management/jmxremote.password.template\n",
      "jdk-11/conf/management/management.properties\n",
      "jdk-11/conf/net.properties\n",
      "jdk-11/conf/security/java.policy\n",
      "jdk-11/conf/security/java.security\n",
      "jdk-11/conf/security/policy/README.txt\n",
      "jdk-11/conf/security/policy/limited/default_US_export.policy\n",
      "jdk-11/conf/security/policy/limited/default_local.policy\n",
      "jdk-11/conf/security/policy/limited/exempt_local.policy\n",
      "jdk-11/conf/security/policy/unlimited/default_US_export.policy\n",
      "jdk-11/conf/security/policy/unlimited/default_local.policy\n",
      "jdk-11/conf/sound.properties\n",
      "jdk-11/include/classfile_constants.h\n",
      "jdk-11/include/jawt.h\n",
      "jdk-11/include/jdwpTransport.h\n",
      "jdk-11/include/jni.h\n",
      "jdk-11/include/jvmti.h\n",
      "jdk-11/include/jvmticmlr.h\n",
      "jdk-11/include/linux/jawt_md.h\n",
      "jdk-11/include/linux/jni_md.h\n",
      "jdk-11/jmods/java.base.jmod\n",
      "jdk-11/jmods/java.compiler.jmod\n",
      "jdk-11/jmods/java.datatransfer.jmod\n",
      "jdk-11/jmods/java.desktop.jmod\n",
      "jdk-11/jmods/java.instrument.jmod\n",
      "jdk-11/jmods/java.logging.jmod\n",
      "jdk-11/jmods/java.management.jmod\n",
      "jdk-11/jmods/java.management.rmi.jmod\n",
      "jdk-11/jmods/java.naming.jmod\n",
      "jdk-11/jmods/java.net.http.jmod\n",
      "jdk-11/jmods/java.prefs.jmod\n",
      "jdk-11/jmods/java.rmi.jmod\n",
      "jdk-11/jmods/java.scripting.jmod\n",
      "jdk-11/jmods/java.se.jmod\n",
      "jdk-11/jmods/java.security.jgss.jmod\n",
      "jdk-11/jmods/java.security.sasl.jmod\n",
      "jdk-11/jmods/java.smartcardio.jmod\n",
      "jdk-11/jmods/java.sql.jmod\n",
      "jdk-11/jmods/java.sql.rowset.jmod\n",
      "jdk-11/jmods/java.transaction.xa.jmod\n",
      "jdk-11/jmods/java.xml.crypto.jmod\n",
      "jdk-11/jmods/java.xml.jmod\n",
      "jdk-11/jmods/jdk.accessibility.jmod\n",
      "jdk-11/jmods/jdk.aot.jmod\n",
      "jdk-11/jmods/jdk.attach.jmod\n",
      "jdk-11/jmods/jdk.charsets.jmod\n",
      "jdk-11/jmods/jdk.compiler.jmod\n",
      "jdk-11/jmods/jdk.crypto.cryptoki.jmod\n",
      "jdk-11/jmods/jdk.crypto.ec.jmod\n",
      "jdk-11/jmods/jdk.dynalink.jmod\n",
      "jdk-11/jmods/jdk.editpad.jmod\n",
      "jdk-11/jmods/jdk.hotspot.agent.jmod\n",
      "jdk-11/jmods/jdk.httpserver.jmod\n",
      "jdk-11/jmods/jdk.internal.ed.jmod\n",
      "jdk-11/jmods/jdk.internal.jvmstat.jmod\n",
      "jdk-11/jmods/jdk.internal.le.jmod\n",
      "jdk-11/jmods/jdk.internal.opt.jmod\n",
      "jdk-11/jmods/jdk.internal.vm.ci.jmod\n",
      "jdk-11/jmods/jdk.internal.vm.compiler.jmod\n",
      "jdk-11/jmods/jdk.internal.vm.compiler.management.jmod\n",
      "jdk-11/jmods/jdk.jartool.jmod\n",
      "jdk-11/jmods/jdk.javadoc.jmod\n",
      "jdk-11/jmods/jdk.jcmd.jmod\n",
      "jdk-11/jmods/jdk.jconsole.jmod\n",
      "jdk-11/jmods/jdk.jdeps.jmod\n",
      "jdk-11/jmods/jdk.jdi.jmod\n",
      "jdk-11/jmods/jdk.jdwp.agent.jmod\n",
      "jdk-11/jmods/jdk.jfr.jmod\n",
      "jdk-11/jmods/jdk.jlink.jmod\n",
      "jdk-11/jmods/jdk.jshell.jmod\n",
      "jdk-11/jmods/jdk.jsobject.jmod\n",
      "jdk-11/jmods/jdk.jstatd.jmod\n",
      "jdk-11/jmods/jdk.localedata.jmod\n",
      "jdk-11/jmods/jdk.management.agent.jmod\n",
      "jdk-11/jmods/jdk.management.jfr.jmod\n",
      "jdk-11/jmods/jdk.management.jmod\n",
      "jdk-11/jmods/jdk.naming.dns.jmod\n",
      "jdk-11/jmods/jdk.naming.rmi.jmod\n",
      "jdk-11/jmods/jdk.net.jmod\n",
      "jdk-11/jmods/jdk.pack.jmod\n",
      "jdk-11/jmods/jdk.rmic.jmod\n",
      "jdk-11/jmods/jdk.scripting.nashorn.jmod\n",
      "jdk-11/jmods/jdk.scripting.nashorn.shell.jmod\n",
      "jdk-11/jmods/jdk.sctp.jmod\n",
      "jdk-11/jmods/jdk.security.auth.jmod\n",
      "jdk-11/jmods/jdk.security.jgss.jmod\n",
      "jdk-11/jmods/jdk.unsupported.desktop.jmod\n",
      "jdk-11/jmods/jdk.unsupported.jmod\n",
      "jdk-11/jmods/jdk.xml.dom.jmod\n",
      "jdk-11/jmods/jdk.zipfs.jmod\n",
      "jdk-11/legal/java.base/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.base/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.base/LICENSE\n",
      "jdk-11/legal/java.base/aes.md\n",
      "jdk-11/legal/java.base/asm.md\n",
      "jdk-11/legal/java.base/c-libutl.md\n",
      "jdk-11/legal/java.base/cldr.md\n",
      "jdk-11/legal/java.base/icu.md\n",
      "jdk-11/legal/java.base/public_suffix.md\n",
      "jdk-11/legal/java.base/unicode.md\n",
      "jdk-11/legal/java.compiler/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.compiler/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.compiler/LICENSE\n",
      "jdk-11/legal/java.datatransfer/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.datatransfer/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.datatransfer/LICENSE\n",
      "jdk-11/legal/java.desktop/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.desktop/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.desktop/LICENSE\n",
      "jdk-11/legal/java.desktop/colorimaging.md\n",
      "jdk-11/legal/java.desktop/giflib.md\n",
      "jdk-11/legal/java.desktop/harfbuzz.md\n",
      "jdk-11/legal/java.desktop/jpeg.md\n",
      "jdk-11/legal/java.desktop/lcms.md\n",
      "jdk-11/legal/java.desktop/libpng.md\n",
      "jdk-11/legal/java.desktop/mesa3d.md\n",
      "jdk-11/legal/java.desktop/opengl.md\n",
      "jdk-11/legal/java.desktop/xwindows.md\n",
      "jdk-11/legal/java.instrument/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.instrument/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.instrument/LICENSE\n",
      "jdk-11/legal/java.logging/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.logging/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.logging/LICENSE\n",
      "jdk-11/legal/java.management.rmi/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.management.rmi/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.management.rmi/LICENSE\n",
      "jdk-11/legal/java.management/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.management/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.management/LICENSE\n",
      "jdk-11/legal/java.naming/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.naming/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.naming/LICENSE\n",
      "jdk-11/legal/java.net.http/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.net.http/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.net.http/LICENSE\n",
      "jdk-11/legal/java.prefs/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.prefs/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.prefs/LICENSE\n",
      "jdk-11/legal/java.rmi/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.rmi/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.rmi/LICENSE\n",
      "jdk-11/legal/java.scripting/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.scripting/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.scripting/LICENSE\n",
      "jdk-11/legal/java.se/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.se/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.se/LICENSE\n",
      "jdk-11/legal/java.security.jgss/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.security.jgss/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.security.jgss/LICENSE\n",
      "jdk-11/legal/java.security.sasl/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.security.sasl/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.security.sasl/LICENSE\n",
      "jdk-11/legal/java.smartcardio/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.smartcardio/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.smartcardio/LICENSE\n",
      "jdk-11/legal/java.smartcardio/pcsclite.md\n",
      "jdk-11/legal/java.sql.rowset/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.sql.rowset/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.sql.rowset/LICENSE\n",
      "jdk-11/legal/java.sql/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.sql/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.sql/LICENSE\n",
      "jdk-11/legal/java.transaction.xa/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.transaction.xa/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.transaction.xa/LICENSE\n",
      "jdk-11/legal/java.xml.crypto/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.xml.crypto/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.xml.crypto/LICENSE\n",
      "jdk-11/legal/java.xml.crypto/santuario.md\n",
      "jdk-11/legal/java.xml/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/java.xml/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/java.xml/LICENSE\n",
      "jdk-11/legal/java.xml/bcel.md\n",
      "jdk-11/legal/java.xml/dom.md\n",
      "jdk-11/legal/java.xml/jcup.md\n",
      "jdk-11/legal/java.xml/xalan.md\n",
      "jdk-11/legal/java.xml/xerces.md\n",
      "jdk-11/legal/jdk.accessibility/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.accessibility/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.accessibility/LICENSE\n",
      "jdk-11/legal/jdk.aot/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.aot/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.aot/LICENSE\n",
      "jdk-11/legal/jdk.attach/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.attach/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.attach/LICENSE\n",
      "jdk-11/legal/jdk.charsets/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.charsets/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.charsets/LICENSE\n",
      "jdk-11/legal/jdk.compiler/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.compiler/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.compiler/LICENSE\n",
      "jdk-11/legal/jdk.crypto.cryptoki/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.crypto.cryptoki/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.crypto.cryptoki/LICENSE\n",
      "jdk-11/legal/jdk.crypto.cryptoki/pkcs11cryptotoken.md\n",
      "jdk-11/legal/jdk.crypto.cryptoki/pkcs11wrapper.md\n",
      "jdk-11/legal/jdk.crypto.ec/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.crypto.ec/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.crypto.ec/LICENSE\n",
      "jdk-11/legal/jdk.crypto.ec/ecc.md\n",
      "jdk-11/legal/jdk.dynalink/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.dynalink/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.dynalink/LICENSE\n",
      "jdk-11/legal/jdk.dynalink/dynalink.md\n",
      "jdk-11/legal/jdk.editpad/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.editpad/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.editpad/LICENSE\n",
      "jdk-11/legal/jdk.hotspot.agent/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.hotspot.agent/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.hotspot.agent/LICENSE\n",
      "jdk-11/legal/jdk.httpserver/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.httpserver/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.httpserver/LICENSE\n",
      "jdk-11/legal/jdk.internal.ed/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.ed/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.ed/LICENSE\n",
      "jdk-11/legal/jdk.internal.jvmstat/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.jvmstat/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.jvmstat/LICENSE\n",
      "jdk-11/legal/jdk.internal.le/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.le/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.le/LICENSE\n",
      "jdk-11/legal/jdk.internal.le/jline.md\n",
      "jdk-11/legal/jdk.internal.opt/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.opt/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.opt/LICENSE\n",
      "jdk-11/legal/jdk.internal.opt/jopt-simple.md\n",
      "jdk-11/legal/jdk.internal.vm.ci/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.vm.ci/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.vm.ci/LICENSE\n",
      "jdk-11/legal/jdk.internal.vm.compiler.management/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.vm.compiler.management/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.vm.compiler.management/LICENSE\n",
      "jdk-11/legal/jdk.internal.vm.compiler/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.internal.vm.compiler/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.internal.vm.compiler/LICENSE\n",
      "jdk-11/legal/jdk.jartool/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jartool/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jartool/LICENSE\n",
      "jdk-11/legal/jdk.javadoc/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.javadoc/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.javadoc/LICENSE\n",
      "jdk-11/legal/jdk.javadoc/jquery-migrate.md\n",
      "jdk-11/legal/jdk.javadoc/jquery.md\n",
      "jdk-11/legal/jdk.javadoc/jqueryUI.md\n",
      "jdk-11/legal/jdk.javadoc/jszip.md\n",
      "jdk-11/legal/jdk.javadoc/pako.md\n",
      "jdk-11/legal/jdk.jcmd/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jcmd/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jcmd/LICENSE\n",
      "jdk-11/legal/jdk.jconsole/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jconsole/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jconsole/LICENSE\n",
      "jdk-11/legal/jdk.jdeps/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jdeps/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jdeps/LICENSE\n",
      "jdk-11/legal/jdk.jdi/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jdi/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jdi/LICENSE\n",
      "jdk-11/legal/jdk.jdwp.agent/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jdwp.agent/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jdwp.agent/LICENSE\n",
      "jdk-11/legal/jdk.jfr/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jfr/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jfr/LICENSE\n",
      "jdk-11/legal/jdk.jlink/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jlink/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jlink/LICENSE\n",
      "jdk-11/legal/jdk.jshell/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jshell/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jshell/LICENSE\n",
      "jdk-11/legal/jdk.jsobject/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jsobject/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jsobject/LICENSE\n",
      "jdk-11/legal/jdk.jstatd/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.jstatd/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.jstatd/LICENSE\n",
      "jdk-11/legal/jdk.localedata/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.localedata/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.localedata/LICENSE\n",
      "jdk-11/legal/jdk.localedata/cldr.md\n",
      "jdk-11/legal/jdk.localedata/thaidict.md\n",
      "jdk-11/legal/jdk.management.agent/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.management.agent/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.management.agent/LICENSE\n",
      "jdk-11/legal/jdk.management.jfr/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.management.jfr/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.management.jfr/LICENSE\n",
      "jdk-11/legal/jdk.management/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.management/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.management/LICENSE\n",
      "jdk-11/legal/jdk.naming.dns/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.naming.dns/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.naming.dns/LICENSE\n",
      "jdk-11/legal/jdk.naming.rmi/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.naming.rmi/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.naming.rmi/LICENSE\n",
      "jdk-11/legal/jdk.net/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.net/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.net/LICENSE\n",
      "jdk-11/legal/jdk.pack/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.pack/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.pack/LICENSE\n",
      "jdk-11/legal/jdk.rmic/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.rmic/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.rmic/LICENSE\n",
      "jdk-11/legal/jdk.scripting.nashorn.shell/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.scripting.nashorn.shell/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.scripting.nashorn.shell/LICENSE\n",
      "jdk-11/legal/jdk.scripting.nashorn/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.scripting.nashorn/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.scripting.nashorn/LICENSE\n",
      "jdk-11/legal/jdk.scripting.nashorn/double-conversion.md\n",
      "jdk-11/legal/jdk.scripting.nashorn/joni.md\n",
      "jdk-11/legal/jdk.sctp/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.sctp/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.sctp/LICENSE\n",
      "jdk-11/legal/jdk.security.auth/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.security.auth/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.security.auth/LICENSE\n",
      "jdk-11/legal/jdk.security.jgss/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.security.jgss/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.security.jgss/LICENSE\n",
      "jdk-11/legal/jdk.unsupported.desktop/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.unsupported.desktop/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.unsupported.desktop/LICENSE\n",
      "jdk-11/legal/jdk.unsupported/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.unsupported/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.unsupported/LICENSE\n",
      "jdk-11/legal/jdk.xml.dom/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.xml.dom/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.xml.dom/LICENSE\n",
      "jdk-11/legal/jdk.zipfs/ADDITIONAL_LICENSE_INFO\n",
      "jdk-11/legal/jdk.zipfs/ASSEMBLY_EXCEPTION\n",
      "jdk-11/legal/jdk.zipfs/LICENSE\n",
      "jdk-11/lib/classlist\n",
      "jdk-11/lib/ct.sym\n",
      "jdk-11/lib/jexec\n",
      "jdk-11/lib/jfr/default.jfc\n",
      "jdk-11/lib/jfr/profile.jfc\n",
      "jdk-11/lib/jli/libjli.so\n",
      "jdk-11/lib/jrt-fs.jar\n",
      "jdk-11/lib/jvm.cfg\n",
      "jdk-11/lib/libattach.so\n",
      "jdk-11/lib/libawt.so\n",
      "jdk-11/lib/libawt_headless.so\n",
      "jdk-11/lib/libawt_xawt.so\n",
      "jdk-11/lib/libdt_socket.so\n",
      "jdk-11/lib/libextnet.so\n",
      "jdk-11/lib/libfontmanager.so\n",
      "jdk-11/lib/libinstrument.so\n",
      "jdk-11/lib/libj2gss.so\n",
      "jdk-11/lib/libj2pcsc.so\n",
      "jdk-11/lib/libj2pkcs11.so\n",
      "jdk-11/lib/libjaas.so\n",
      "jdk-11/lib/libjava.so\n",
      "jdk-11/lib/libjavajpeg.so\n",
      "jdk-11/lib/libjawt.so\n",
      "jdk-11/lib/libjdwp.so\n",
      "jdk-11/lib/libjimage.so\n",
      "jdk-11/lib/libjsig.so\n",
      "jdk-11/lib/libjsound.so\n",
      "jdk-11/lib/liblcms.so\n",
      "jdk-11/lib/libmanagement.so\n",
      "jdk-11/lib/libmanagement_agent.so\n",
      "jdk-11/lib/libmanagement_ext.so\n",
      "jdk-11/lib/libmlib_image.so\n",
      "jdk-11/lib/libnet.so\n",
      "jdk-11/lib/libnio.so\n",
      "jdk-11/lib/libprefs.so\n",
      "jdk-11/lib/librmi.so\n",
      "jdk-11/lib/libsaproc.so\n",
      "jdk-11/lib/libsctp.so\n",
      "jdk-11/lib/libsplashscreen.so\n",
      "jdk-11/lib/libsunec.so\n",
      "jdk-11/lib/libunpack.so\n",
      "jdk-11/lib/libverify.so\n",
      "jdk-11/lib/libzip.so\n",
      "jdk-11/lib/modules\n",
      "jdk-11/lib/psfont.properties.ja\n",
      "jdk-11/lib/psfontj2d.properties\n",
      "jdk-11/lib/security/blacklisted.certs\n",
      "jdk-11/lib/security/cacerts\n",
      "jdk-11/lib/security/default.policy\n",
      "jdk-11/lib/security/public_suffix_list.dat\n",
      "jdk-11/lib/server/Xusage.txt\n",
      "jdk-11/lib/server/libjsig.so\n",
      "jdk-11/lib/server/libjvm.so\n",
      "jdk-11/lib/src.zip\n",
      "jdk-11/lib/tzdb.dat\n",
      "jdk-11/release\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for Java installation\n",
    "!mkdir -p /root/java\n",
    "\n",
    "# Download the Java JDK\n",
    "!wget -P /root/java https://download.java.net/openjdk/jdk11/ri/openjdk-11+28_linux-x64_bin.tar.gz\n",
    "\n",
    "# Extract the downloaded JDK\n",
    "!tar --no-same-owner -xvzf /root/java/openjdk-11+28_linux-x64_bin.tar.gz -C /root/java/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java path: /root/java/jdk-11/bin/java\n",
      "Java version output: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openjdk version \"11\" 2018-09-25\n",
      "OpenJDK Runtime Environment 18.9 (build 11+28)\n",
      "OpenJDK 64-Bit Server VM 18.9 (build 11+28, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set JAVA_HOME to the extracted JDK directory\n",
    "java_home = \"/root/java/jdk-11\"\n",
    "if not os.path.exists(java_home):\n",
    "    raise RuntimeError(f\"Java home directory does not exist: {java_home}\")\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = java_home\n",
    "os.environ[\"PATH\"] = os.path.join(java_home, \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Verify that java is in the PATH\n",
    "java_path = os.popen('which java').read().strip()\n",
    "print(f\"Java path: {java_path}\")\n",
    "\n",
    "# Check if the Java command works\n",
    "java_version_output = os.popen('java -version').read()\n",
    "print(f\"Java version output: {java_version_output}\")\n",
    "\n",
    "# Set the SPARK_VERSION environment variable\n",
    "os.environ[\"SPARK_VERSION\"] = \"3.3.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker_pyspark\n",
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import pydeequ\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using the NYC TLC Trip Record Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_url = \"s3a://nyc-tlc/trip data/yellow_tripdata_2022-01.parquet\"\n",
    "\n",
    "# Read the Parquet file into a Spark DataFrame\n",
    "df = spark.read.parquet(s3_url)\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis \n",
    "\n",
    "Before we define checks on the data, we want to calculate some statistics on the dataset; we call them metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     entity|            instance|               name|               value|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     Column|          long trips|         Compliance| 0.06526116194000563|\n",
      "|     Column|       trip_distance|               Mean|    5.37275119311366|\n",
      "|    Dataset|                   *|               Size|           2463931.0|\n",
      "|     Column|            VendorID|       Completeness|                 1.0|\n",
      "|Multicolumn|total_amount,fare...|        Correlation|  0.9998747962656196|\n",
      "|Multicolumn|fare_amount,trip_...|        Correlation|4.057810518341101...|\n",
      "|     Column|            VendorID|ApproxCountDistinct|                 4.0|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis with PyDeequ\n",
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"VendorID\")) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"VendorID\")) \\\n",
    "                    .addAnalyzer(Mean(\"trip_distance\")) \\\n",
    "                    .addAnalyzer(Compliance(\"long trips\", \"trip_distance >= 10.0\")) \\\n",
    "                    .addAnalyzer(Correlation(\"fare_amount\", \"trip_distance\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_amount\", \"fare_amount\")) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also get that result in a Pandas Dataframe!\n",
    "\n",
    "Passing `pandas=True` in any call for getting metrics as DataFrames will return the dataframe in Pandas form! We'll see more of it down the line! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>long trips</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>6.526116e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>Mean</td>\n",
       "      <td>5.372751e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>2.463931e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column</td>\n",
       "      <td>VendorID</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multicolumn</td>\n",
       "      <td>total_amount,fare_amount</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>9.998748e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multicolumn</td>\n",
       "      <td>fare_amount,trip_distance</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>4.057811e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column</td>\n",
       "      <td>VendorID</td>\n",
       "      <td>ApproxCountDistinct</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                   instance                 name         value\n",
       "0       Column                 long trips           Compliance  6.526116e-02\n",
       "1       Column              trip_distance                 Mean  5.372751e+00\n",
       "2      Dataset                          *                 Size  2.463931e+06\n",
       "3       Column                   VendorID         Completeness  1.000000e+00\n",
       "4  Multicolumn   total_amount,fare_amount          Correlation  9.998748e-01\n",
       "5  Multicolumn  fare_amount,trip_distance          Correlation  4.057811e-04\n",
       "6       Column                   VendorID  ApproxCountDistinct  4.000000e+00"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysisResult_pd_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult, pandas=True)\n",
    "analysisResult_pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data metrics, we learned the following:\n",
    "\n",
    "- **Compliance of Long Trips**: Only 6.53% of trips are classified as long trips.\n",
    "- **Mean Trip Distance**: The average trip distance is approximately 5.37 miles.\n",
    "- **Dataset Size**: The dataset contains approximately 2,463,931 records.\n",
    "- **VendorID Completeness**: The `VendorID` column is 100% complete, with no missing values.\n",
    "- **Correlation between Total Amount and Fare Amount**: There is a very high correlation (0.9999) between `total_amount` and `fare_amount`, indicating that these two variables are almost perfectly correlated.\n",
    "- **Correlation between Fare Amount and Trip Distance**: There is a very low correlation (0.0004) between `fare_amount` and `trip_distance`, indicating little to no linear relationship between these variables.\n",
    "- **Approximate Count of Distinct VendorIDs**: There are approximately 4 distinct values in the `VendorID` column.\n",
    "\n",
    "\n",
    "\n",
    "## Define and Run Tests for Data\n",
    "\n",
    "After analyzing and understanding the data, we want to verify that the properties we have derived also hold for new versions of the dataset. By defining assertions on the data distribution as part of a data pipeline, we can ensure that every processed dataset is of high quality, and that any application consuming the data can rely on it.\n",
    "\n",
    "For writing tests on data, we start with the _VerificationSuite (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/VerificationSuite.scala)_ and add _Checks (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/checks/Check.scala)_ on attributes of the data. \n",
    "\n",
    "In this example, we test for the following properties of our data:\n",
    "\n",
    "* There are at least 2 million rows in total.\n",
    "* `VendorID` is never NULL.\n",
    "* `VendorID` is unique.\n",
    "* `VendorID` only contains the values \"2\", \"1\", \"6\", or \"5\".\n",
    "* `payment_type` is never NULL.\n",
    "* `payment_type` only contains the values \"1\" or \"2\", and at least 96% of the values must meet this criteria.\n",
    "* `DOLocationID` is never NULL and does not contain negative values.\n",
    "* `improvement_surcharge` is never NULL.\n",
    "* `tpep_dropoff_datetime` is never NULL.\n",
    "* `PULocationID` is never NULL and does not contain negative values.\n",
    "* `trip_distance` is never NULL and does not contain negative values.\n",
    "* `tolls_amount` is never NULL.\n",
    "\n",
    "This is the code that reflects the previous statements. For information about all available checks, see _this GitHub repository (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/checks/Check.scala)_. You can run this directly in the Spark shell as previously explained:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 181:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Run Status: Warning\n",
      "                       check check_level check_status  \\\n",
      "0   NYC TLC Trip Record Data     Warning      Warning   \n",
      "1   NYC TLC Trip Record Data     Warning      Warning   \n",
      "2   NYC TLC Trip Record Data     Warning      Warning   \n",
      "3   NYC TLC Trip Record Data     Warning      Warning   \n",
      "4   NYC TLC Trip Record Data     Warning      Warning   \n",
      "5   NYC TLC Trip Record Data     Warning      Warning   \n",
      "6   NYC TLC Trip Record Data     Warning      Warning   \n",
      "7   NYC TLC Trip Record Data     Warning      Warning   \n",
      "8   NYC TLC Trip Record Data     Warning      Warning   \n",
      "9   NYC TLC Trip Record Data     Warning      Warning   \n",
      "10  NYC TLC Trip Record Data     Warning      Warning   \n",
      "11  NYC TLC Trip Record Data     Warning      Warning   \n",
      "12  NYC TLC Trip Record Data     Warning      Warning   \n",
      "13  NYC TLC Trip Record Data     Warning      Warning   \n",
      "14  NYC TLC Trip Record Data     Warning      Warning   \n",
      "\n",
      "                                           constraint constraint_status  \\\n",
      "0                          SizeConstraint(Size(None))           Success   \n",
      "1   CompletenessConstraint(Completeness(VendorID,N...           Success   \n",
      "2   UniquenessConstraint(Uniqueness(List(VendorID)...           Failure   \n",
      "3   ComplianceConstraint(Compliance(VendorID conta...           Success   \n",
      "4   CompletenessConstraint(Completeness(payment_ty...           Success   \n",
      "5   ComplianceConstraint(Compliance(payment_type c...           Success   \n",
      "6   CompletenessConstraint(Completeness(DOLocation...           Success   \n",
      "7   ComplianceConstraint(Compliance(DOLocationID i...           Success   \n",
      "8   CompletenessConstraint(Completeness(improvemen...           Success   \n",
      "9   CompletenessConstraint(Completeness(tpep_dropo...           Success   \n",
      "10  CompletenessConstraint(Completeness(PULocation...           Success   \n",
      "11  ComplianceConstraint(Compliance(PULocationID i...           Success   \n",
      "12  CompletenessConstraint(Completeness(trip_dista...           Success   \n",
      "13  ComplianceConstraint(Compliance(trip_distance ...           Success   \n",
      "14  CompletenessConstraint(Completeness(tolls_amou...           Success   \n",
      "\n",
      "                                   constraint_message  \n",
      "0                                                      \n",
      "1                                                      \n",
      "2   Value: 0.0 does not meet the constraint requir...  \n",
      "3                                                      \n",
      "4                                                      \n",
      "5                                                      \n",
      "6                                                      \n",
      "7                                                      \n",
      "8                                                      \n",
      "9                                                      \n",
      "10                                                     \n",
      "11                                                     \n",
      "12                                                     \n",
      "13                                                     \n",
      "14                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "\n",
    "# Define the check\n",
    "check = Check(spark, CheckLevel.Warning, \"NYC TLC Trip Record Data\")\n",
    "\n",
    "# Run the verification suite with the defined checks\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 2000000) \\\n",
    "        .isComplete(\"VendorID\") \\\n",
    "        .isUnique(\"VendorID\") \\\n",
    "        .isContainedIn(\"VendorID\", [\"2\", \"1\", \"6\", \"5\"]) \\\n",
    "        .isComplete(\"payment_type\") \\\n",
    "        .isContainedIn(\"payment_type\", [\"1\", \"2\"], lambda x: x >= 0.96, \"It should be above 0.96!\") \\\n",
    "        .isComplete(\"DOLocationID\") \\\n",
    "        .isNonNegative(\"DOLocationID\") \\\n",
    "        .isComplete(\"improvement_surcharge\") \\\n",
    "        .isComplete(\"tpep_dropoff_datetime\") \\\n",
    "        .isComplete(\"PULocationID\") \\\n",
    "        .isNonNegative(\"PULocationID\") \\\n",
    "        .isComplete(\"trip_distance\") \\\n",
    "        .isNonNegative(\"trip_distance\") \\\n",
    "        .isComplete(\"tolls_amount\")) \\\n",
    "    .run()\n",
    "\n",
    "\n",
    "# Print the verification run status\n",
    "print(f\"Verification Run Status: {checkResult.status}\")\n",
    "\n",
    "# Convert the check results to a DataFrame and display it\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult, pandas=True)\n",
    "print(checkResult_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the verification suite, PyDeequ translated the test descriptions into a series of Spark jobs to compute metrics on the NYC TLC Trip Record Data. The verification run status was \"Warning,\" indicating some checks did not fully pass.\n",
    "\n",
    "Here's a concise summary of the results:\n",
    "\n",
    "- **Size Check**: Passed, with the data having at least 2,000,000 records.\n",
    "- **Completeness Checks**: All columns (`VendorID`, `payment_type`, `DOLocationID`, `improvement_surcharge`, `tpep_dropoff_datetime`, `PULocationID`, `trip_distance`, `tolls_amount`) passed their completeness checks.\n",
    "- **Uniqueness Check**: Failed for `VendorID`, indicating the values are not unique.\n",
    "- **Value Containment Check**: Passed for both `VendorID` and `payment_type` (with the latter requiring at least 96% of values within [\"1\", \"2\"]).\n",
    "- **Non-Negativity Checks**: Passed for `DOLocationID`, `PULocationID`, and `trip_distance`.\n",
    "\n",
    "Interestingly, the `VendorID` column failed the uniqueness check, showing that it does not have unique values, as indicated by the failure message. All other constraints were successfully met.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>improvement_surcharge</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>PULocationID is non-negative</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Column</td>\n",
       "      <td>tpep_dropoff_datetime</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column</td>\n",
       "      <td>payment_type</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column</td>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Column</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column</td>\n",
       "      <td>trip_distance is non-negative</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Column</td>\n",
       "      <td>VendorID contained in 2,1,6,5</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Column</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>2.463931e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Column</td>\n",
       "      <td>VendorID</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Column</td>\n",
       "      <td>payment_type contained in 1,2</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>9.618958e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Column</td>\n",
       "      <td>DOLocationID is non-negative</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Column</td>\n",
       "      <td>PULocationID</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity                       instance          name         value\n",
       "0    Column          improvement_surcharge  Completeness  1.000000e+00\n",
       "1    Column   PULocationID is non-negative    Compliance  1.000000e+00\n",
       "2    Column          tpep_dropoff_datetime  Completeness  1.000000e+00\n",
       "3    Column                   payment_type  Completeness  1.000000e+00\n",
       "4    Column                   DOLocationID  Completeness  1.000000e+00\n",
       "5    Column                   tolls_amount  Completeness  1.000000e+00\n",
       "6    Column  trip_distance is non-negative    Compliance  1.000000e+00\n",
       "7    Column  VendorID contained in 2,1,6,5    Compliance  1.000000e+00\n",
       "8    Column                  trip_distance  Completeness  1.000000e+00\n",
       "9   Dataset                              *          Size  2.463931e+06\n",
       "10   Column                       VendorID  Completeness  1.000000e+00\n",
       "11   Column  payment_type contained in 1,2    Compliance  9.618958e-01\n",
       "12   Column   DOLocationID is non-negative    Compliance  1.000000e+00\n",
       "13   Column                   PULocationID  Completeness  1.000000e+00"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkResult_df = VerificationResult.successMetricsAsDataFrame(spark, checkResult, pandas=True)\n",
    "checkResult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Constraint Suggestion \n",
    "\n",
    "If you own a large number of datasets or if your dataset has many columns, it may be challenging for you to manually define appropriate constraints. Deequ can automatically suggest useful constraints based on the data distribution. Deequ first runs a data profiling method and then applies a set of rules on the result. For more information about how to run a data profiling method, see _this GitHub repository. (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/data_profiling_example.md)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"constraint_suggestions\": [\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(DOLocationID,None,None))\",\n",
      "      \"column_name\": \"DOLocationID\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'DOLocationID' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"DOLocationID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('DOLocationID' has no negative values,DOLocationID >= 0,None,List(DOLocationID),None))\",\n",
      "      \"column_name\": \"DOLocationID\",\n",
      "      \"current_value\": \"Minimum: 1.0\",\n",
      "      \"description\": \"'DOLocationID' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"DOLocationID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(improvement_surcharge,None,None))\",\n",
      "      \"column_name\": \"improvement_surcharge\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'improvement_surcharge' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"improvement_surcharge\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(tpep_dropoff_datetime,None,None))\",\n",
      "      \"column_name\": \"tpep_dropoff_datetime\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'tpep_dropoff_datetime' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"tpep_dropoff_datetime\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(PULocationID,None,None))\",\n",
      "      \"column_name\": \"PULocationID\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'PULocationID' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"PULocationID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('PULocationID' has no negative values,PULocationID >= 0,None,List(PULocationID),None))\",\n",
      "      \"column_name\": \"PULocationID\",\n",
      "      \"current_value\": \"Minimum: 1.0\",\n",
      "      \"description\": \"'PULocationID' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"PULocationID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(trip_distance,None,None))\",\n",
      "      \"column_name\": \"trip_distance\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'trip_distance' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"trip_distance\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('trip_distance' has no negative values,trip_distance >= 0,None,List(trip_distance),None))\",\n",
      "      \"column_name\": \"trip_distance\",\n",
      "      \"current_value\": \"Minimum: 0.0\",\n",
      "      \"description\": \"'trip_distance' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"trip_distance\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(tolls_amount,None,None))\",\n",
      "      \"column_name\": \"tolls_amount\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'tolls_amount' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"tolls_amount\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('RatecodeID' has no negative values,RatecodeID >= 0,None,List(RatecodeID),None))\",\n",
      "      \"column_name\": \"RatecodeID\",\n",
      "      \"current_value\": \"Minimum: 1.0\",\n",
      "      \"description\": \"'RatecodeID' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"RatecodeID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(RatecodeID,None,None))\",\n",
      "      \"column_name\": \"RatecodeID\",\n",
      "      \"current_value\": \"Completeness: 0.9709801126736097\",\n",
      "      \"description\": \"'RatecodeID' has less than 3% missing values\",\n",
      "      \"suggesting_rule\": \"RetainCompletenessRule()\",\n",
      "      \"rule_description\": \"If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness\",\n",
      "      \"code_for_constraint\": \".hasCompleteness(\\\"RatecodeID\\\", lambda x: x >= 0.97, \\\"It should be above 0.97!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('VendorID' has value range '2', '1', '6', '5',`VendorID` IN ('2', '1', '6', '5'),None,List(VendorID),None))\",\n",
      "      \"column_name\": \"VendorID\",\n",
      "      \"current_value\": \"Compliance: 1\",\n",
      "      \"description\": \"'VendorID' has value range '2', '1', '6', '5'\",\n",
      "      \"suggesting_rule\": \"CategoricalRangeRule(com.amazon.deequ.suggestions.rules.CategoricalRangeRule$$$Lambda$4155/0x00000001015e1040@63abfe4c)\",\n",
      "      \"rule_description\": \"If we see a categorical range for a column, we suggest an IS IN (...) constraint\",\n",
      "      \"code_for_constraint\": \".isContainedIn(\\\"VendorID\\\", [\\\"2\\\", \\\"1\\\", \\\"6\\\", \\\"5\\\"])\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(VendorID,None,None))\",\n",
      "      \"column_name\": \"VendorID\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'VendorID' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"VendorID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('VendorID' has value range '2', '1' for at least 99.0% of values,`VendorID` IN ('2', '1'),None,List(VendorID),None))\",\n",
      "      \"column_name\": \"VendorID\",\n",
      "      \"current_value\": \"Compliance: 0.9977276149372689\",\n",
      "      \"description\": \"'VendorID' has value range '2', '1' for at least 99.0% of values\",\n",
      "      \"suggesting_rule\": \"FractionalCategoricalRangeRule(0.9,com.amazon.deequ.suggestions.rules.FractionalCategoricalRangeRule$$$Lambda$4156/0x00000001015e0840@130842a4)\",\n",
      "      \"rule_description\": \"If we see a categorical range for most values in a column, we suggest an IS IN (...) constraint that should hold for most values\",\n",
      "      \"code_for_constraint\": \".isContainedIn(\\\"VendorID\\\", [\\\"2\\\", \\\"1\\\"], lambda x: x >= 0.99, \\\"It should be above 0.99!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('VendorID' has no negative values,VendorID >= 0,None,List(VendorID),None))\",\n",
      "      \"column_name\": \"VendorID\",\n",
      "      \"current_value\": \"Minimum: 1.0\",\n",
      "      \"description\": \"'VendorID' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"VendorID\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(tip_amount,None,None))\",\n",
      "      \"column_name\": \"tip_amount\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'tip_amount' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"tip_amount\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(payment_type,None,None))\",\n",
      "      \"column_name\": \"payment_type\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'payment_type' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"payment_type\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('payment_type' has value range '1', '2' for at least 96.0% of values,`payment_type` IN ('1', '2'),None,List(payment_type),None))\",\n",
      "      \"column_name\": \"payment_type\",\n",
      "      \"current_value\": \"Compliance: 0.96189584854446\",\n",
      "      \"description\": \"'payment_type' has value range '1', '2' for at least 96.0% of values\",\n",
      "      \"suggesting_rule\": \"FractionalCategoricalRangeRule(0.9,com.amazon.deequ.suggestions.rules.FractionalCategoricalRangeRule$$$Lambda$4156/0x00000001015e0840@130842a4)\",\n",
      "      \"rule_description\": \"If we see a categorical range for most values in a column, we suggest an IS IN (...) constraint that should hold for most values\",\n",
      "      \"code_for_constraint\": \".isContainedIn(\\\"payment_type\\\", [\\\"1\\\", \\\"2\\\"], lambda x: x >= 0.96, \\\"It should be above 0.96!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('payment_type' has no negative values,payment_type >= 0,None,List(payment_type),None))\",\n",
      "      \"column_name\": \"payment_type\",\n",
      "      \"current_value\": \"Minimum: 0.0\",\n",
      "      \"description\": \"'payment_type' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"payment_type\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(fare_amount,None,None))\",\n",
      "      \"column_name\": \"fare_amount\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'fare_amount' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"fare_amount\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('passenger_count' has no negative values,passenger_count >= 0,None,List(passenger_count),None))\",\n",
      "      \"column_name\": \"passenger_count\",\n",
      "      \"current_value\": \"Minimum: 0.0\",\n",
      "      \"description\": \"'passenger_count' has no negative values\",\n",
      "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
      "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
      "      \"code_for_constraint\": \".isNonNegative(\\\"passenger_count\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(passenger_count,None,None))\",\n",
      "      \"column_name\": \"passenger_count\",\n",
      "      \"current_value\": \"Completeness: 0.9709801126736097\",\n",
      "      \"description\": \"'passenger_count' has less than 3% missing values\",\n",
      "      \"suggesting_rule\": \"RetainCompletenessRule()\",\n",
      "      \"rule_description\": \"If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness\",\n",
      "      \"code_for_constraint\": \".hasCompleteness(\\\"passenger_count\\\", lambda x: x >= 0.97, \\\"It should be above 0.97!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('store_and_fwd_flag' has value range 'N', 'Y',`store_and_fwd_flag` IN ('N', 'Y'),None,List(store_and_fwd_flag),None))\",\n",
      "      \"column_name\": \"store_and_fwd_flag\",\n",
      "      \"current_value\": \"Compliance: 1\",\n",
      "      \"description\": \"'store_and_fwd_flag' has value range 'N', 'Y'\",\n",
      "      \"suggesting_rule\": \"CategoricalRangeRule(com.amazon.deequ.suggestions.rules.CategoricalRangeRule$$$Lambda$4155/0x00000001015e1040@63abfe4c)\",\n",
      "      \"rule_description\": \"If we see a categorical range for a column, we suggest an IS IN (...) constraint\",\n",
      "      \"code_for_constraint\": \".isContainedIn(\\\"store_and_fwd_flag\\\", [\\\"N\\\", \\\"Y\\\"])\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"ComplianceConstraint(Compliance('store_and_fwd_flag' has value range 'N' for at least 94.0% of values,`store_and_fwd_flag` IN ('N'),None,List(store_and_fwd_flag),None))\",\n",
      "      \"column_name\": \"store_and_fwd_flag\",\n",
      "      \"current_value\": \"Compliance: 0.9486856571876404\",\n",
      "      \"description\": \"'store_and_fwd_flag' has value range 'N' for at least 94.0% of values\",\n",
      "      \"suggesting_rule\": \"FractionalCategoricalRangeRule(0.9,com.amazon.deequ.suggestions.rules.FractionalCategoricalRangeRule$$$Lambda$4156/0x00000001015e0840@130842a4)\",\n",
      "      \"rule_description\": \"If we see a categorical range for most values in a column, we suggest an IS IN (...) constraint that should hold for most values\",\n",
      "      \"code_for_constraint\": \".isContainedIn(\\\"store_and_fwd_flag\\\", [\\\"N\\\"], lambda x: x >= 0.94, \\\"It should be above 0.94!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(store_and_fwd_flag,None,None))\",\n",
      "      \"column_name\": \"store_and_fwd_flag\",\n",
      "      \"current_value\": \"Completeness: 0.9709801126736097\",\n",
      "      \"description\": \"'store_and_fwd_flag' has less than 3% missing values\",\n",
      "      \"suggesting_rule\": \"RetainCompletenessRule()\",\n",
      "      \"rule_description\": \"If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness\",\n",
      "      \"code_for_constraint\": \".hasCompleteness(\\\"store_and_fwd_flag\\\", lambda x: x >= 0.97, \\\"It should be above 0.97!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(extra,None,None))\",\n",
      "      \"column_name\": \"extra\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'extra' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"extra\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(airport_fee,None,None))\",\n",
      "      \"column_name\": \"airport_fee\",\n",
      "      \"current_value\": \"Completeness: 0.9709801126736097\",\n",
      "      \"description\": \"'airport_fee' has less than 3% missing values\",\n",
      "      \"suggesting_rule\": \"RetainCompletenessRule()\",\n",
      "      \"rule_description\": \"If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness\",\n",
      "      \"code_for_constraint\": \".hasCompleteness(\\\"airport_fee\\\", lambda x: x >= 0.97, \\\"It should be above 0.97!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(congestion_surcharge,None,None))\",\n",
      "      \"column_name\": \"congestion_surcharge\",\n",
      "      \"current_value\": \"Completeness: 0.9709801126736097\",\n",
      "      \"description\": \"'congestion_surcharge' has less than 3% missing values\",\n",
      "      \"suggesting_rule\": \"RetainCompletenessRule()\",\n",
      "      \"rule_description\": \"If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness\",\n",
      "      \"code_for_constraint\": \".hasCompleteness(\\\"congestion_surcharge\\\", lambda x: x >= 0.97, \\\"It should be above 0.97!\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(total_amount,None,None))\",\n",
      "      \"column_name\": \"total_amount\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'total_amount' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"total_amount\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(tpep_pickup_datetime,None,None))\",\n",
      "      \"column_name\": \"tpep_pickup_datetime\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'tpep_pickup_datetime' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"tpep_pickup_datetime\\\")\"\n",
      "    },\n",
      "    {\n",
      "      \"constraint_name\": \"CompletenessConstraint(Completeness(mta_tax,None,None))\",\n",
      "      \"column_name\": \"mta_tax\",\n",
      "      \"current_value\": \"Completeness: 1.0\",\n",
      "      \"description\": \"'mta_tax' is not null\",\n",
      "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
      "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
      "      \"code_for_constraint\": \".isComplete(\\\"mta_tax\\\")\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.suggestions import *\n",
    "\n",
    "suggestionResult = ConstraintSuggestionRunner(spark) \\\n",
    "             .onData(df) \\\n",
    "             .addConstraintRule(DEFAULT()) \\\n",
    "             .run()\n",
    "\n",
    "# Constraint Suggestions in JSON format\n",
    "print(json.dumps(suggestionResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result contains a list of constraints with descriptions and Python code, so that you can directly apply it in your data quality checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples on GitHub\n",
    "\n",
    "You can find examples of more advanced features at _Deequ’s GitHub page (https://github.com/awslabs/deequ)_:\n",
    "\n",
    "* Deequ not only provides data quality checks with fixed thresholds. Learn how to use _anomaly detection on data quality metrics (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/anomaly_detection_example.md)_ to apply tests on metrics that change over time.\n",
    "* Deequ offers support for storing and loading metrics. Learn how to use the _MetricsRepository (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/metrics_repository_example.md)_ for this use case.\n",
    "* If your dataset grows over time or is partitioned, you can use Deequ’s _incremental metrics computation (https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/algebraic_states_example.md)_ capability. For each partition, Deequ stores a state for each computed metric. To compute metrics for the union of partitions, Deequ can use these states to efficiently derive overall metrics without reloading the data.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "Learn more about the inner workings of Deequ in the VLDB 2018 paper “_Automating large-scale data quality verification. (http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf)_”\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This blog post showed you how to use PyDeequ for calculating data quality metrics, verifying data quality metrics, and profiling data to automate the configuration of data quality checks. PyDeequ is available for you now to build your own data quality management pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
